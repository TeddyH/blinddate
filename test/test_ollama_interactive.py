#!/usr/bin/env python3
"""
Ollama ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì‹¤ì œ ì±„íŒ…ì²˜ëŸ¼ ëŒ€í™”ë¥¼ ì£¼ê³ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""

import requests
import json
import sys

OLLAMA_URL = "http://localhost:11434/api/chat"
MODEL = "llama3.2:3b"  # ê¸°ë³¸ ëª¨ë¸ (ëª…ë ¹ì¤„ ì¸ìë¡œ ë³€ê²½ ê°€ëŠ¥)

def print_colored(text, color_code):
    """ì»¬ëŸ¬ ì¶œë ¥"""
    print(f"\033[{color_code}m{text}\033[0m")

def chat_interactive():
    """ëŒ€í™”í˜• ì±„íŒ… ì¸í„°í˜ì´ìŠ¤"""
    print("="*60)
    print_colored(f"Ollama ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸ ({MODEL})", "1;36")
    print("="*60)
    print_colored("ëª…ë ¹ì–´:", "1;33")
    print("  /exit ë˜ëŠ” /quit : ì¢…ë£Œ")
    print("  /clear : ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”")
    print("  /history : í˜„ì¬ ëŒ€í™” íˆìŠ¤í† ë¦¬ ë³´ê¸°")
    print("  /system [ë©”ì‹œì§€] : ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •")
    print("="*60 + "\n")

    # ëŒ€í™” íˆìŠ¤í† ë¦¬
    messages = []
    system_prompt = "ë‹¹ì‹ ì€ ì¹œê·¼í•œ í•œêµ­ ë°ì´íŒ… ì•±ì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ìì—°ìŠ¤ëŸ½ê³  ì¡´ì¤‘í•˜ëŠ” íƒœë„ë¡œ ëŒ€í™”í•˜ì„¸ìš”."

    # ì´ˆê¸° ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    messages.append({
        "role": "system",
        "content": system_prompt
    })

    print_colored(f"[ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •ë¨]\n{system_prompt}\n", "0;35")

    while True:
        try:
            # ì‚¬ìš©ì ì…ë ¥
            user_input = input("\033[1;32më‹¹ì‹ : \033[0m")

            # ë¹ˆ ì…ë ¥ ë¬´ì‹œ
            if not user_input.strip():
                continue

            # ëª…ë ¹ì–´ ì²˜ë¦¬
            if user_input.lower() in ['/exit', '/quit']:
                print_colored("\nğŸ‘‹ ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.", "1;33")
                break

            elif user_input.lower() == '/clear':
                messages = [{
                    "role": "system",
                    "content": system_prompt
                }]
                print_colored("\nğŸ§¹ ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\n", "1;33")
                continue

            elif user_input.lower() == '/history':
                print_colored("\nğŸ“œ ëŒ€í™” íˆìŠ¤í† ë¦¬:", "1;33")
                for i, msg in enumerate(messages, 1):
                    role = msg['role']
                    content = msg['content'][:100] + "..." if len(msg['content']) > 100 else msg['content']
                    print(f"{i}. [{role}] {content}")
                print()
                continue

            elif user_input.lower().startswith('/system '):
                new_system = user_input[8:].strip()
                if new_system:
                    system_prompt = new_system
                    messages[0] = {
                        "role": "system",
                        "content": system_prompt
                    }
                    print_colored(f"\nâœ… ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë³€ê²½ë¨:\n{system_prompt}\n", "0;35")
                continue

            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            messages.append({
                "role": "user",
                "content": user_input
            })

            # Ollama API í˜¸ì¶œ
            payload = {
                "model": MODEL,
                "messages": messages,
                "stream": True  # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
            }

            print("\033[1;34mAI: \033[0m", end="", flush=True)

            response = requests.post(OLLAMA_URL, json=payload, stream=True)

            if response.status_code != 200:
                print_colored(f"\nâŒ ì—ëŸ¬: {response.status_code}", "1;31")
                print(response.text)
                messages.pop()  # ì‹¤íŒ¨í•œ ë©”ì‹œì§€ ì œê±°
                continue

            # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì¶œë ¥
            full_response = ""
            for line in response.iter_lines():
                if line:
                    chunk = json.loads(line)
                    if 'message' in chunk:
                        content = chunk['message']['content']
                        full_response += content
                        print(content, end="", flush=True)

                    if chunk.get('done', False):
                        # ë©”íƒ€ë°ì´í„° ì¶œë ¥ (ì˜µì…˜)
                        eval_count = chunk.get('eval_count', 0)
                        total_duration = chunk.get('total_duration', 0) / 1e9

                        print()  # ì¤„ë°”ê¿ˆ
                        print_colored(
                            f"  [í† í°: {eval_count} | ì‹œê°„: {total_duration:.2f}ì´ˆ]",
                            "0;90"
                        )
                        break

            # AI ì‘ë‹µì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            messages.append({
                "role": "assistant",
                "content": full_response
            })

            print()  # ë¹ˆ ì¤„

        except KeyboardInterrupt:
            print_colored("\n\nâš ï¸  Ctrl+C ê°ì§€. /exit ë¡œ ì¢…ë£Œí•˜ì„¸ìš”.\n", "1;33")
            continue

        except Exception as e:
            print_colored(f"\nâŒ ì—ëŸ¬ ë°œìƒ: {e}\n", "1;31")
            import traceback
            traceback.print_exc()


def check_server():
    """ì„œë²„ ì—°ê²° í™•ì¸"""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=2)
        if response.status_code == 200:
            models = response.json().get('models', [])
            model_names = [m['name'] for m in models]

            if not any(MODEL in name for name in model_names):
                print_colored(f"âš ï¸  '{MODEL}' ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "1;33")
                print("\nì„¤ì¹˜ëœ ëª¨ë¸:")
                for name in model_names:
                    print(f"  - {name}")
                print(f"\në‹¤ìŒ ëª…ë ¹ì–´ë¡œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”:")
                print(f"  $ ollama pull {MODEL}")
                return False

            return True
    except requests.exceptions.ConnectionError:
        print_colored("âŒ Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "1;31")
        print("\në‹¤ìŒ ëª…ë ¹ì–´ë¡œ Ollamaë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:")
        print("  $ ollama serve")
        return False
    except Exception as e:
        print_colored(f"âŒ ì—ëŸ¬: {e}", "1;31")
        return False


if __name__ == "__main__":
    # ëª…ë ¹ì¤„ ì¸ìë¡œ ëª¨ë¸ ì„ íƒ ê°€ëŠ¥
    if len(sys.argv) > 1:
        MODEL = sys.argv[1]
        print_colored(f"ğŸ¤– ì„ íƒëœ ëª¨ë¸: {MODEL}\n", "1;36")

    if check_server():
        chat_interactive()
    else:
        sys.exit(1)
