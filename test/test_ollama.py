#!/usr/bin/env python3
"""
Ollama API í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
llama3.2:3b ëª¨ë¸ì„ ì‚¬ìš©í•œ ê°„ë‹¨í•œ ëŒ€í™” í…ŒìŠ¤íŠ¸
"""

import requests
import json
import sys

# Ollama API ì—”ë“œí¬ì¸íŠ¸
OLLAMA_URL = "http://localhost:11434/api/chat"
MODEL = "llama3.2:3b"  # ê¸°ë³¸ ëª¨ë¸ (ëª…ë ¹ì¤„ ì¸ìë¡œ ë³€ê²½ ê°€ëŠ¥)

def test_single_message():
    """ë‹¨ì¼ ë©”ì‹œì§€ í…ŒìŠ¤íŠ¸ (ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ)"""
    print("\n" + "="*50)
    print("í…ŒìŠ¤íŠ¸ 1: ë‹¨ì¼ ë©”ì‹œì§€ (ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ)")
    print("="*50)

    payload = {
        "model": MODEL,
        "messages": [
            {
                "role": "user",
                "content": "ì•ˆë…•? ë‚´ ì´ë¦„ì€ ì² ìˆ˜ì•¼."
            }
        ],
        "stream": False
    }

    response = requests.post(OLLAMA_URL, json=payload)

    if response.status_code == 200:
        result = response.json()
        print(f"ì‚¬ìš©ì: {payload['messages'][0]['content']}")
        print(f"AI: {result['message']['content']}")
        print(f"\në©”íƒ€ë°ì´í„°:")
        print(f"  - ëª¨ë¸: {result.get('model', 'N/A')}")
        print(f"  - ì´ í† í°: {result.get('eval_count', 'N/A')}")
        print(f"  - ìƒì„± ì‹œê°„: {result.get('total_duration', 0) / 1e9:.2f}ì´ˆ")
    else:
        print(f"âŒ ì—ëŸ¬: {response.status_code}")
        print(response.text)


def test_context_without_history():
    """ì»¨í…ìŠ¤íŠ¸ ì—†ì´ ì´ì–´ì§€ëŠ” ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ (ì‹¤íŒ¨ ì˜ˆìƒ)"""
    print("\n" + "="*50)
    print("í…ŒìŠ¤íŠ¸ 2: ì»¨í…ìŠ¤íŠ¸ ì—†ì´ ì´ì–´ì§€ëŠ” ì§ˆë¬¸ (ê¸°ì–µ ëª»í•¨)")
    print("="*50)

    # ì²« ë²ˆì§¸ ë©”ì‹œì§€
    payload1 = {
        "model": MODEL,
        "messages": [
            {"role": "user", "content": "ë‚´ ì´ë¦„ì€ ì² ìˆ˜ì•¼."}
        ],
        "stream": False
    }

    response1 = requests.post(OLLAMA_URL, json=payload1)
    result1 = response1.json()
    print(f"ì‚¬ìš©ì: ë‚´ ì´ë¦„ì€ ì² ìˆ˜ì•¼.")
    print(f"AI: {result1['message']['content']}\n")

    # ë‘ ë²ˆì§¸ ë©”ì‹œì§€ (íˆìŠ¤í† ë¦¬ ì—†ìŒ)
    payload2 = {
        "model": MODEL,
        "messages": [
            {"role": "user", "content": "ë‚´ ì´ë¦„ì´ ë­ì•¼?"}
        ],
        "stream": False
    }

    response2 = requests.post(OLLAMA_URL, json=payload2)
    result2 = response2.json()
    print(f"ì‚¬ìš©ì: ë‚´ ì´ë¦„ì´ ë­ì•¼?")
    print(f"AI: {result2['message']['content']}")
    print(f"âŒ ì˜ˆìƒëŒ€ë¡œ ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ì§€ ëª»í•¨")


def test_context_with_history():
    """ì „ì²´ íˆìŠ¤í† ë¦¬ë¥¼ í¬í•¨í•œ ëŒ€í™” í…ŒìŠ¤íŠ¸ (ì„±ê³µ ì˜ˆìƒ)"""
    print("\n" + "="*50)
    print("í…ŒìŠ¤íŠ¸ 3: íˆìŠ¤í† ë¦¬ í¬í•¨ ëŒ€í™” (ê¸°ì–µí•¨)")
    print("="*50)

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì¶•
    messages = []

    # ì²« ë²ˆì§¸ ëŒ€í™”
    messages.append({"role": "user", "content": "ë‚´ ì´ë¦„ì€ ì² ìˆ˜ì•¼."})

    payload = {
        "model": MODEL,
        "messages": messages,
        "stream": False
    }

    response = requests.post(OLLAMA_URL, json=payload)
    result = response.json()
    assistant_msg = result['message']['content']

    print(f"ì‚¬ìš©ì: ë‚´ ì´ë¦„ì€ ì² ìˆ˜ì•¼.")
    print(f"AI: {assistant_msg}\n")

    # AI ì‘ë‹µì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
    messages.append({"role": "assistant", "content": assistant_msg})

    # ë‘ ë²ˆì§¸ ëŒ€í™” (íˆìŠ¤í† ë¦¬ í¬í•¨)
    messages.append({"role": "user", "content": "ë‚´ ì´ë¦„ì´ ë­ì•¼?"})

    payload = {
        "model": MODEL,
        "messages": messages,
        "stream": False
    }

    response = requests.post(OLLAMA_URL, json=payload)
    result = response.json()

    print(f"ì‚¬ìš©ì: ë‚´ ì´ë¦„ì´ ë­ì•¼?")
    print(f"AI: {result['message']['content']}")
    print(f"âœ… ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•¨!")


def test_conversation_with_system_prompt():
    """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ í¬í•¨í•œ ëŒ€í™” í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*50)
    print("í…ŒìŠ¤íŠ¸ 4: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + ëŒ€í™”")
    print("="*50)

    messages = [
        {
            "role": "system",
            "content": "ë‹¹ì‹ ì€ ì¹œê·¼í•œ í•œêµ­ ë°ì´íŒ… ì•±ì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì¡´ì¤‘í•˜ê³  ë”°ëœ»í•œ íƒœë„ë¡œ ëŒ€í™”í•˜ì„¸ìš”."
        },
        {
            "role": "user",
            "content": "ì˜¤ëŠ˜ ì²« ë°ì´íŠ¸ì¸ë° ë­˜ ì…ì–´ì•¼ í• ê¹Œ?"
        }
    ]

    payload = {
        "model": MODEL,
        "messages": messages,
        "stream": False
    }

    response = requests.post(OLLAMA_URL, json=payload)
    result = response.json()

    print(f"ì‹œìŠ¤í…œ: {messages[0]['content']}\n")
    print(f"ì‚¬ìš©ì: {messages[1]['content']}")
    print(f"AI: {result['message']['content']}")


def test_streaming():
    """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*50)
    print("í…ŒìŠ¤íŠ¸ 5: ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ")
    print("="*50)

    payload = {
        "model": MODEL,
        "messages": [
            {"role": "user", "content": "ë°ì´íŒ… ì•±ì—ì„œ ì²« ì¸ì‚¬ ë©”ì‹œì§€ë¥¼ ì–´ë–»ê²Œ ë³´ë‚´ë©´ ì¢‹ì„ê¹Œ?"}
        ],
        "stream": True
    }

    print("ì‚¬ìš©ì: ë°ì´íŒ… ì•±ì—ì„œ ì²« ì¸ì‚¬ ë©”ì‹œì§€ë¥¼ ì–´ë–»ê²Œ ë³´ë‚´ë©´ ì¢‹ì„ê¹Œ?")
    print("AI: ", end="", flush=True)

    response = requests.post(OLLAMA_URL, json=payload, stream=True)

    full_response = ""
    for line in response.iter_lines():
        if line:
            chunk = json.loads(line)
            if 'message' in chunk:
                content = chunk['message']['content']
                full_response += content
                print(content, end="", flush=True)

            if chunk.get('done', False):
                print()  # ì¤„ë°”ê¿ˆ
                break


def test_multi_turn_conversation():
    """ì—¬ëŸ¬ í„´ì˜ ëŒ€í™” í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*50)
    print("í…ŒìŠ¤íŠ¸ 6: ë©€í‹°í„´ ëŒ€í™” (3í„´)")
    print("="*50)

    messages = [
        {
            "role": "system",
            "content": "ë‹¹ì‹ ì€ ë°ì´íŒ… ì•±ì˜ AI ëŒ€í™” ì—°ìŠµ íŒŒíŠ¸ë„ˆì…ë‹ˆë‹¤. ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ì„¸ìš”."
        }
    ]

    user_messages = [
        "ì•ˆë…•í•˜ì„¸ìš”! í”„ë¡œí•„ ë´¤ëŠ”ë° ì˜í™” ì¢‹ì•„í•˜ì‹ ë‹¤ê³ ìš”?",
        "ì €ëŠ” ì•¡ì…˜ ì˜í™”ë¥¼ ì¢‹ì•„í•˜ëŠ”ë°, í˜¹ì‹œ ìµœê·¼ì— ë³¸ ì˜í™” ìˆìœ¼ì„¸ìš”?",
        "ì˜¤ ì €ë„ ê·¸ ì˜í™” ì¬ë¯¸ìˆê²Œ ë´¤ì–´ìš”! ì£¼ë§ì— ì‹œê°„ ë˜ì‹œë©´ ê°™ì´ ì˜í™” ë³´ëŠ” ê±´ ì–´ë•Œìš”?"
    ]

    for i, user_msg in enumerate(user_messages, 1):
        messages.append({"role": "user", "content": user_msg})

        payload = {
            "model": MODEL,
            "messages": messages,
            "stream": False
        }

        response = requests.post(OLLAMA_URL, json=payload)
        result = response.json()
        assistant_msg = result['message']['content']

        print(f"\n[í„´ {i}]")
        print(f"ì‚¬ìš©ì: {user_msg}")
        print(f"AI: {assistant_msg}")

        # AI ì‘ë‹µì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        messages.append({"role": "assistant", "content": assistant_msg})


def check_ollama_status():
    """Ollama ì„œë²„ ìƒíƒœ í™•ì¸"""
    print("\n" + "="*50)
    print("Ollama ì„œë²„ ìƒíƒœ í™•ì¸")
    print("="*50)

    try:
        # ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ í™•ì¸
        response = requests.get("http://localhost:11434/api/tags")
        if response.status_code == 200:
            models = response.json()
            print("âœ… Ollama ì„œë²„ ì‹¤í–‰ ì¤‘")
            print("\nì„¤ì¹˜ëœ ëª¨ë¸:")
            for model in models.get('models', []):
                print(f"  - {model['name']} ({model['size'] / 1e9:.2f} GB)")
                if model['name'].startswith('llama3.2:3b'):
                    print(f"    âœ… í…ŒìŠ¤íŠ¸ ëª¨ë¸ ë°œê²¬!")
        else:
            print(f"âš ï¸  Ollama ì‘ë‹µ ì´ìƒ: {response.status_code}")
    except requests.exceptions.ConnectionError:
        print("âŒ Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ Ollamaë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:")
        print("   $ ollama serve")
        return False

    return True


if __name__ == "__main__":
    # ëª…ë ¹ì¤„ ì¸ìë¡œ ëª¨ë¸ ì„ íƒ ê°€ëŠ¥
    if len(sys.argv) > 1:
        MODEL = sys.argv[1]

    print("=" * 50)
    print("Ollama API í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    print(f"ğŸ¤– ì‚¬ìš© ëª¨ë¸: {MODEL}")
    print("=" * 50)

    # ì„œë²„ ìƒíƒœ í™•ì¸
    if not check_ollama_status():
        exit(1)

    try:
        # ê° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        test_single_message()
        test_context_without_history()
        test_context_with_history()
        test_conversation_with_system_prompt()
        test_streaming()
        test_multi_turn_conversation()

        print("\n" + "="*50)
        print("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print(f"ğŸ¤– ì‚¬ìš©í•œ ëª¨ë¸: {MODEL}")
        print("="*50)

    except KeyboardInterrupt:
        print("\n\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        print(f"\nâŒ ì—ëŸ¬ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
